对于张量运算所操作的张量，其元素可以被解释为某种几何空间内点的坐标.
神经网络完全由一系列张量运算组成，而这些张量运算都只是输入数据的几何变换。
因此，你可以将神经网络解释为高维空间中非常复杂的几何变换，这种变换可以通过许多简单的步骤来实现。

训练循环过程：
(1) 抽取训练样本x 和对应目标y 组成的数据批量。
(2) 在x 上运行网络［这一步叫作前向传播（forward pass）］，得到预测值y_pred。
(3) 计算网络在这批数据上的损失，用于衡量y_pred 和y 之间的距离。
(4) 更新网络的所有权重，使网络在这批数据上的损失略微下降。
最终得到的网络在训练数据上的损失非常小，即预测值y_pred 和预期目标y 之间的距离
非常小。网络“学会”将输入映射到正确的目标。
梯度（gradient）是张量运算的导数。

小批量随机梯度下降算法步骤：
(1) 抽取训练样本x 和对应目标y 组成的数据批量。
(2) 在x 上运行网络，得到预测值y_pred。
(3) 计算网络在这批数据上的损失，用于衡量y_pred 和y 之间的距离。
(4) 计算损失相对于网络参数的梯度［一次反向传播（backward pass）］。
(5) 将参数沿着梯度的反方向移动一点，比如W -= step * gradient，从而使这批数据
上的损失减小一点。
术语随机（stochastic）是指每批数据都是随机抽取的。
注意，小批量SGD 算法的一个变体是每次迭代时只抽取一个样本和目标，而不是抽取一批
数据。这叫作真SGD（有别于小批量SGD）。还有另一种极端，每一次迭代都在所有数据上
运行，这叫作批量SGD。这样做的话，每次更新都更加准确，但计算代价也高得多。这两个极
端之间的有效折中则是选择合理的批量大小。
SGD 还有多种变体，其区别在于计算下一次权重更新时还要考虑上一次权重更新，
而不是仅仅考虑当前梯度值，比如带动量的SGD、Adagrad、RMSProp 等变体。这些变体被称
为优化方法（optimization method）或优化器（optimizer）。其中动量的概念尤其值得关注，它在
许多变体中都有应用。动量解决了SGD 的两个问题：收敛速度和局部极小点。

在某个参数值附近，有一个局部极小点（local minimum）：在这个点附近，向
左移动和向右移动都会导致损失值增大。如果使用小学习率的SGD 进行优化，那么优化过程可
能会陷入局部极小点，导致无法找到全局最小点。
使用动量方法可以避免这样的问题，这一方法的灵感来源于物理学。有一种有用的思维图像，
就是将优化过程想象成一个小球从损失函数曲线上滚下来。如果小球的动量足够大，那么它不会
卡在峡谷里，最终会到达全局最小点。动量方法的实现过程是每一步都移动小球，不仅要考虑当
前的斜率值（当前的加速度），还要考虑当前的速度（来自于之前的加速度）。这在实践中的是指，
更新参数w 不仅要考虑当前的梯度值，还要考虑上一次的参数更新

2.4.4链式求导：反向传播算法
将链式法则应用于神经网络梯度值的计算，得到的算法叫作反向传播
（backpropagation，有时也叫反式微分，reverse-mode differentiation）。反
向传播从最终损失值开始，从最顶层反向作用至最底层，利用链式法则计算每个参数对损失值
的贡献大小。现在以及未来数年，人们将使用能够进行符号微分（symbolic differentiation）的现代框架来
实现神经网络，比如TensorFlow。也就是说，给定一个运算链，并且已知每个运算的导数，这
些框架就可以利用链式法则来计算这个运算链的梯度函数，将网络参数值映射为梯度值。对于
这样的函数，反向传播就简化为调用这个梯度函数。由于符号微分的出现，你无须手动实现反
向传播算法。因此，我们不会在本节浪费你的时间和精力来推导反向传播的具体公式。你只需
充分理解基于梯度的优化方法的工作原理。

本章小结
（1）学习是指找到一组模型参数，使得在给定的训练数据样本和对应目标值上的损失函数最
小化。
（2） 学习的过程：随机选取包含数据样本及其目标值的批量，并计算批量损失相对于网络参
数的梯度。随后将网络参数沿着梯度的反方向稍稍移动（移动距离由学习率指定）。
（3） 整个学习过程之所以能够实现，是因为神经网络是一系列可微分的张量运算，因此可以
利用求导的链式法则来得到梯度函数，这个函数将当前参数和当前数据批量映射为一个
梯度值。
（4） 后续几章你会经常遇到两个关键的概念：损失和优化器。将数据输入网络之前，你需要
先定义这二者。
（5） 损失是在训练过程中需要最小化的量，因此，它应该能够衡量当前任务是否已成功解决。
（6） 优化器是使用损失梯度更新参数的具体方式，比如 RMSProp 优化器、带动量的随机梯
度下降（SGD）等。

3.1　神经网络剖析
前面几章介绍过，训练神经网络主要围绕以下四个方面。
1、层，多个层组合成网络（或模型）。
2、输入数据和相应的目标。
3、 损失函数，即用于学习的反馈信号。
4、 优化器，决定学习过程如何进行。

四者的关系如下：多个层链接在一起组成了网络，将输入数据映射为预测值。然后损失函数将
这些预测值与目标进行比较，得到损失值，用于衡量网络预测值与预期结果的匹配程度。
优化器使用这个损失值来更新网络的权重。

3.1.1　层：深度学习的基础组件
神经网络的基本数据结构是层。层是一个数据处理模块，将一个或多个输入张量转换为一个或多个输出张量。
有些层是无状态的，但大多数的层是有状态的，即层的权重。权重是利用随机梯度下降学到的一个或多个张量，
其中包含网络的知识。不同的张量格式与不同的数据处理类型需要用到不同的层。例如，简单的向量数据保存在
形状为 的2D 张量中，通常用密集连接层［也叫全连接层或密集层，对应于Keras的Dense类］来处理。
序列数据保存在形状为的3D 张量中，通常用循环层（比如Keras 的LSTM 层）来处理。图像数据保存在4D 张量中，
通常用二维卷积层（Keras 的Conv2D）来处理。你可以将层看作深度学习的乐高积木，Keras等框架则将这种比喻具体化。
在Keras 中，构建深度学习模型就是将相互兼容的多个层拼接在一起，以建立有用的数据变换流程。这里层兼
容性具体指的是每一层只接受特定形状的输入张量，并返回特定形状的输出张量。

3.1.2　模型：层构成的网络
深度学习模型是层构成的有向无环图。最常见的例子就是层的线性堆叠，将单一输入映射
为单一输出。
但随着深入学习，你会接触到更多类型的网络拓扑结构。一些常见的网络拓扑结构如下。
1 双分支网络
2 多头网络
3 Inception模块
网络的拓扑结构定义了一个假设空间。选定了网络拓扑结构，意味着将可能性空间
（假设空间）限定为一系列特定的张量运算，将输入数据映射为输出数据。然后，你需要为这些张量运算的权重张量找到一组合适的值。
选择正确的网络架构更像是一门艺术而不是科学。
3.1.3　损失函数与优化器：配置学习过程的关键
一旦确定了网络架构，你还需要选择以下两个参数。
1 损失函数（也就是目标函数）——在训练过程中需要将其最小化。它能够衡量当前任务是否已
成功完成。
2 优化器——决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（SGD）
的某个变体。具有多个输出的神经网络可能具有多个损失函数（每个输出对应一个损失函数）。
但是，梯度下降过程必须基于单个标量损失值。因此，对于具有多个损失函数的网络，需要将所有损失
函数取平均，变为一个标量值。
选择正确的目标函数对解决问题是非常重要的。网络的目的是使损失尽可能最小化，因此，
如果目标函数与成功完成当前任务不完全相关，那么网络最终得到的结果可能会不符合你的预
期。一定要明智地选择目标函数，否则你将会遇到意想不到的副作用。
幸运的是，对于分类、回归、序列预测等常见问题，你可以遵循一些简单的指导原则来选
择正确的损失函数。例如，对于二分类问题，你可以使用二元交叉熵损失函数；对于多分类问题，可以用分类交叉熵损失函数；对于回归
问题，可以用均方误差损失函数；对于序列学习问题，可以用联结主义时序分类损失函数。只有在面对真正全新的研究问题时，你才需要自主开发目标函数。

Keras 具有以下重要特性。
1、相同的代码可以在 CPU或 GPU 上无缝切换运行。
2、具有用户友好的 API，便于快速开发深度学习模型的原型。
3、内置支持卷积网络（用于计算机视觉）、循环网络（用于序列处理）以及二者的任意组合。
4、支持任意网络架构：多输入或多输出模型、层共享、模型共享等。这也就是说，Keras
能够构建任意深度学习模型，无论是生成式对抗网络还是神经图灵机。

Keras 是一个模型级的库，为开发深度学习模型提供了高层次的构建模块。
它不处理张量操作、求微分等低层次的运算。相反，它依赖于一个专门的、高度优化的张量库
来完成这些运算，这个张量库就是Keras 的后端引擎。Keras 没有选择单个张
量库并将Keras 实现与这个库绑定，而是以模块化的方式处理这个问题。因此，几
个不同的后端引擎都可以无缝嵌入到Keras中。目前，Keras 有三个后端实现：TensorFlow 后端、
Theano 后端和微软认知工具包（CNTK）后端。
TensorFlow、CNTK 和Theano 是当今深度学习的几个主要平台。
你用Keras 写的每一段代码都可以在这三个后端上运行，无须任何修改。也就是说，你在开发过程中可以在两个后端之
间无缝切换，这通常是很有用的。
通过TensorFlow（或Theano、CNTK），Keras 可以在CPU 和GPU 上无缝运行。在CPU 上运行
时，TensorFlow 本身封装了一个低层次的张量运算库，叫作Eigen；在GPU 上运行时，TensorFlow
封装了一个高度优化的深度学习运算库，叫作NVIDIA CUDA 深度神经网络库（cuDNN）。

Keras开发流程：
(1) 定义训练数据：输入张量和目标张量。
(2) 定义层组成的网络（或模型），将输入映射到目标。
(3) 配置学习过程：选择损失函数、优化器和需要监控的指标。
(4) 调用模型的fit 方法在训练数据上进行迭代。
定义模型有两种方法：一种是使用Sequential 类（仅用于层的线性堆叠，这是目前最常
见的网络架构），另一种是函数式API（functional API，用于层组成的有向无环图，让你可以构
建任意形式的架构）。
一旦定义好了模型架构，使用Sequential 模型还是函数式API 就不重要了。接下来的步
骤都是相同的。
配置学习过程是在编译这一步，你需要指定模型使用的优化器和损失函数，以及训练过程
中想要监控的指标。
最后，学习过程就是通过fit() 方法将输入数据的Numpy 数组（和对应的目标数据）传
入模型，这一做法与Scikit-Learn 及其他机器学习库类似。
不能将整数序列直接输入神经网络。你需要将列表转换为张量。转换方法有以下两种。
第一种为填充列表，使其具有相同的长度，再将列表转换成形状为 (samples, word_indices)
的整数张量，然后网络第一层使用能处理这种整数张量的层（即Embedding 层）。
第二种对列表进行one-hot 编码，将其转换为 0 和 1 组成的向量。

对于这种Dense 层的堆叠，你需要确定以下两个关键架构：
1、网络有多少层；
2、每层有多少个隐藏单元。

relu（整流线性单元）函数将所有负值归零。
而sigmoid 函数则将任意值“压缩”到[0,1] 区间内，其输出值可以看作概率值。

什么是激活函数？为什么要使用激活函数？
如果没有relu 等激活函数（也叫非线性），Dense 层将只包含两个线性运算——点积和加法.
这样Dense 层就只能学习输入数据的线性变换（仿射变换）：该层的假设空间是从输
入数据到16 位空间所有可能的线性变换集合。这种假设空间非常有限，无法利用多个表示
层的优势，因为多个线性层堆叠实现的仍是线性运算，添加层数并不会扩展假设空间。
为了得到更丰富的假设空间，从而充分利用多层表示的优势，你需要添加非线性或激
活函数。relu 是深度学习中最常用的激活函数，但还有许多其他函数可选，它们都有类似
的奇怪名称，比如prelu、elu 等。

注意：
1、通常需要对原始数据进行大量预处理，以便将其转换为张量输入到神经网络中。单词序
列可以编码为二进制向量，但也有其他编码方式。
2、带有relu激活的 Dense 层堆叠，可以解决很多种问题（包括情感分类），你可能会经
常用到这种模型。
3、对于二分类问题（两个输出类别），网络的最后一层应该是只有一个单元并使用sigmoid
激活的Dense 层，网络输出应该是0~1 范围内的标量，表示概率值。
4、对于二分类问题的 sigmoid标量输出，你应该使用binary_crossentropy损失函数。
5、无论你的问题是什么，rmsprop优化器通常都是足够好的选择。这一点你无须担心。
6、随着神经网络在训练数据上的表现越来越好，模型最终会过拟合，并在前所未见的数据
上得到越来越差的结果。一定要一直监控模型在训练集之外的数据上的性能。

选择损失函数和优化器时：由于你面对的是一个二分类问题，网络输出是一
个概率值（网络最后一层使用sigmoid 激活函数，仅包含一个单元），那么最好使用binary_
crossentropy（二元交叉熵）损失。这并不是唯一可行的选择，比如你还可以使用mean_
squared_error（均方误差）。但对于输出概率值的模型，交叉熵（crossentropy）往往是最好
的选择。交叉熵是来自于信息论领域的概念，用于衡量概率分布之间的距离，在这个例子中就
是真实分布与预测值之间的距离。

将标签向量化有两种方法：你可以将标签列表转换为整数张量，或者使用one-hot 编码。
one-hot 编码是分类数据广泛使用的一种格式，也叫分类编码。
另一种编码标签的方法，就是将其转换为整数张量,对于整数标签，你应该使用sparse_categorical_crossentropy。

Dense 层的堆叠，每层只能访问上一层输出的信息。如果某一层丢失了与分类问题相关的一些信息，
那么这些信息无法被后面的层找回，也就是说，每一层都可能成为信息瓶颈。

注意：
1、对于多分类问题，最好的损失函数是categorical_crossentropy（分类交叉熵）。它用于
衡量两个概率分布之间的距离，这里两个概率分布分别是网络输出的概率分布和标签的真实分
布。通过将这两个分布的距离最小化，训练网络可使输出结果尽可能接近真实标签。
2、如果要对 N个类别的数据点进行分类，网络的最后一层应该是大小为N的Dense层。
3、对于单标签、多分类问题，网络的最后一层应该使用softmax 激活，这样可以输出在N
个输出类别上的概率分布。
4、这种问题的损失函数几乎总是应该使用分类交叉熵。它将网络输出的概率分布与目标的
真实分布之间的距离最小化。
5、处理多分类问题的标签有两种方法。
通过分类编码（也叫 one-hot 编码）对标签进行编码，然后使用 categorical_
crossentropy 作为损失函数。 将标签编码为整数，然后使用 sparse_categorical_crossentropy损失函数。
6、如果你需要将数据划分到许多类别中，应该避免使用太小的中间层，以免在网络中造成信息瓶颈。

将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种
取值范围不同的数据，但学习肯定变得更加困难。对于这种数据，普遍采用的最佳实践是对每
个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，再除
以标准差，这样得到的特征平均值为0，标准差为1。用Numpy 可以很容易实现标准化。

注意，用于测试数据标准化的均值和标准差都是在训练数据上计算得到的。在工作流程中，
你不能使用在测试数据上计算得到的任何结果，即使是像数据标准化这么简单的事情也不行。
一般来说，训练数据越少，过拟合会越严重，而较小的网络可以降低过拟合。
网络的最后一层只有一个单元，没有激活，是一个线性层。这是标量回归（标量回归是预
测单一连续值的回归）的典型设置。添加激活函数将会限制输出范围。例如，如果向最后一层
添加sigmoid 激活函数，网络只能学会预测0~1 范围内的值。这里最后一层是纯线性的，所以
网络可以学会预测任意范围内的值。
注意，编译网络用的是mse 损失函数，即均方误差（MSE），预测值与
目标值之差的平方。这是回归问题常用的损失函数。
在训练过程中还监控一个新指标：平均绝对误差（MAE）。它是预测值
与目标值之差的绝对值。

为了在调节网络参数（比如训练的轮数）的同时对网络进行评估，你可以将数据划分为训
练集和验证集，正如前面例子中所做的那样。但由于数据点很少，验证集会非常小（比如大约
100个样本）。因此，验证分数可能会有很大波动，这取决于你所选择的验证集和训练集。也就
是说，验证集的划分方式可能会造成验证分数上有很大的方差，这样就无法对模型进行可靠的
评估。在这种情况下，最佳做法是使用K 折交叉验证。这种方法将可用数据划分为K个分区
（K通常取4或5），实例化K个相同的模型，将每个模型在K-1 个分区上训练，并在剩
下的一个分区上进行评估。模型的验证分数等于K 个验证分数的平均值.

注意：
1、回归问题使用的损失函数与分类问题不同。回归常用的损失函数是均方误差（MSE）。
2、同样，回归问题使用的评估指标也与分类问题不同。显而易见，精度的概念不适用于回
归问题。常见的回归指标是平均绝对误差（MAE）。
3、如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行
缩放。
4、如果可用的数据很少，使用K折验证可以可靠地评估模型。
5、如果可用的训练数据很少，最好使用隐藏层较少（通常只有一到两个）的小型网络，以
避免严重的过拟合。

自监督学习是监督学习的一个特例，它与众不同，值得单独归为一类。自监督学习是没有
人工标注的标签的监督学习，你可以将它看作没有人类参与的监督学习。标签仍然存在（因为
总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生
成的。
举个例子，自编码器是有名的自监督学习的例子，其生成的目标就是未经
修改的输入。同样，给定视频中过去的帧来预测下一帧，或者给定文本中前面的词来预测下一个词，
都是自监督学习的例子［这两个例子也属于时序监督学习，即用未来的输入数据作为监督］。
注意，监督学习、自监督学习和无监督学习之间的区别有时很模糊，这三个类别更像是没有明
确界限的连续体。自监督学习可以被重新解释为监督学习或无监督学习，
这取决于你关注的是学习机制还是应用场景。

在强化学习中，智能体（agent）接收有关其环境的信息，并学会选择使某种奖励最大化的行动。
例如，神经网络会“观察”视频游戏的屏幕并输出游戏操作，目的是尽可能得高分，这种神经
网络可以通过强化学习来训练。

术语：
多分类：一种分类任务，每个输入样本都应被划分到两个以上的类别中，比如手写数字分类。
多标签分类：一种分类任务，每个输入样本都可以分配多个标签。
举个例子，如果一幅图像里可能既有猫又有狗，那么应该同时标注“猫”标签和“狗”标签。每幅图像的标签个数通常是可变的。
标量回归（scalar regression）：目标是连续标量值的任务。预测房价就是一个很好的
例子，不同的目标价格形成一个连续的空间。
向量回归（vector regression）：目标是一组连续值（比如一个连续向量）的任务。如
果对多个值（比如图像边界框的坐标）进行回归，那就是向量回归。
小批量（mini-batch）或批量（batch）：模型同时处理的一小部分样本（样本数通常
为8~128）。样本数通常取2 的幂，这样便于GPU 上的内存分配。训练时，小批量
用来为模型权重计算一次梯度下降更新。

为什么在训练集/测试集之外还需要验证集？
原因在于开发模型时总是需要调节模型配置，比如选择层数或每层大小［这叫作模型的超
参数，以便与模型参数（即权重）区分开］。这个调节过程需要使用模型在验
证数据上的性能作为反馈信号。这个调节过程本质上就是一种学习：在某个参数空间中寻找良
好的模型配置。因此，如果基于模型在验证集上的性能来调节模型配置，会很快导致模型在验
证集上过拟合，即使你并没有在验证集上直接训练模型也会如此。
造成这一现象的关键在于信息泄露。每次基于模型在验证集上的性能来
调节模型超参数，都会有一些关于验证数据的信息泄露到模型中。如果对每个参数只调节一次，
那么泄露的信息很少，验证集仍然可以可靠地评估模型。但如果你多次重复这一过程（运行一
次实验，在验证集上评估，然后据此修改模型），那么将会有越来越多的关于验证集的信息泄露
到模型中。
最后，你得到的模型在验证集上的性能非常好（人为造成的），因为这正是你优化的目的。
你关心的是模型在全新数据上的性能，而不是在验证数据上的性能，因此你需要使用一个完全
不同的、前所未见的数据集来评估模型，它就是测试集。你的模型一定不能读取与测试集有关
的任何信息，既使间接读取也不行。如果基于测试集性能来调节模型，那么对泛化能力的衡量
是不准确的。

数据量较少的时候训练集/测试集/验证集的划分的三种经典的评估方法：
1、简单的留出验证
缺点：如果可用的数据很少，那么可能验证集和测试集
包含的样本就太少，从而无法在统计学上代表数据。
2、K 折验证
3、带有打乱数据的重复K 折验证。
具体做法是多次使用K 折验证，在每次将数据划分为K 个分区之前都先将数据打乱。
最终分数是每次K 折验证分数的平均值。注意，这种方法一共要训练和评估P×K 个模型（P
是重复次数），计算代价很大。

评估模型的注意事项
选择模型评估方法时，需要注意以下几点。
数据代表性 ：你希望训练集和测试集都能够代表当前数据。
例如，你想要对数字图像进行分类，而图像样本是按类别排序的，如果你将前80% 作为训
练集，剩余20% 作为测试集，那么会导致训练集中只包含类别0~7，而测试集中只包含
类别8~9。这个错误看起来很可笑，却很常见。因此，在将数据划分为训练集和测试集
之前，通常应该随机打乱数据。
时间箭头：如果想要根据过去预测未来（比如明天的天气、股票走势
等），那么在划分数据前你不应该随机打乱数据，因为这么做会造成时间泄露，
你的模型将在未来数据上得到有效训练。在这种情况下，你应该始终确保测试集
中所有数据的时间都晚于训练集数据。
数据冗余：如果数据中的某些数据点出现了两次（这在现实中
的数据里十分常见），那么打乱数据并划分成训练集和验证集会导致训练集和验证集之
间的数据冗余。从效果上来看，你是在部分训练数据上评估模型，这是极其糟糕的！一
定要确保训练集和验证集之间没有交集。

数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失
值和特征提取
神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论
处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作数据向量化。

一般来说，将取值相对较大的数据（比如多位整数，比网络权重的初始值大很多）或异质
数据（比如数据的一个特征在0~1 范围内，另一个特征在100~200 范围内）
输入到神经网络中是不安全的。这么做可能导致较大的梯度更新，进而导致网络无法收敛。为
了让网络的学习变得更容易，输入数据应该具有以下特征。
1、取值较小：大部分值都应该在 0~1 范围内。
2、同质性：所有特征的取值都应该在大致相同的范围内。
此外，下面这种更严格的标准化方法也很常见，而且很有用，虽然不一定总是必需的（例如，
对于数字分类问题就不需要这么做）。
1、将每个特征分别标准化，使其平均值为 0。
2、将每个特征分别标准化，使其标准差为 1。

一般来说，对于神经网络，将缺失值设置为0 是安全的，只要0 不是一个有意义的值。网
络能够从数据中学到0 意味着缺失数据，并且会忽略这个值。
注意，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络
不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制
一些训练样本，然后删除测试数据中可能缺失的某些特征。

特征工程是指将数据输入模型之前，利用你自己关于数据和机器学
习算法（这里指神经网络）的知识对数据进行硬编码的变换（不是模型学到的），以改善模型的
效果。多数情况下，一个机器学习模型无法从完全任意的数据中进行学习。呈现给模型的数据
应该便于模型进行学习。

，对于现代深度学习，大部分特征工程都是不需要的，因为神经网络能够从原始
数据中自动提取有用的特征。这是否意味着，只要使用深度神经网络，就无须担心特征工程呢？
并不是这样，原因有两点。
1、良好的特征仍然可以让你用更少的资源更优雅地解决问题。例如，使用卷积神经网络来
读取钟面上的时间是非常可笑的。
2、良好的特征可以让你用更少的数据解决问题。深度学习模型自主学习特征的能力依赖于
大量的训练数据。如果只有很少的样本，那么特征的信息价值就变得非常重要。

训练数据上的损失越小，测试数据上的损失也越小。这时的模型是欠拟合的。
为了防止模型从训练数据中学到错误或无关紧要的模式，最优解决方法是获取更多的训练
数据。模型的训练数据越多，泛化能力自然也越好。如果无法获取更多数据，次优解决方法是
调节模型允许存储的信息量，或对模型允许存储的信息加以约束。如果一个网络只能记住几个
模式，那么优化过程会迫使模型集中学习最重要的模式，这样更可能得到良好的泛化。
这种降低过拟合的方法叫作正则化。

几种最常见的正则化方法：
1、减小网络大小
防止过拟合的最简单的方法就是减小模型大小，即减少模型中可学习参数的个数。
在深度学习中，模型中可学习参数的个数通常被称为模型的容量。
直观上来看，参数更多的模型拥有更大的记忆容量，因此能
够在训练样本和目标之间轻松地学会完美的字典式映射，这种映射没有任何泛化能力。
与此相反，如果网络的记忆资源有限，则无法轻松学会这种映射。因此，为了让损失最小化，
网络必须学会对目标具有很强预测能力的压缩表示，这也正是我们感兴趣的数据表示。同时请
记住，你使用的模型应该具有足够多的参数，以防欠拟合，即模型应避免记忆资源不足。在容
量过大与容量不足之间要找到一个折中。

要找到合适的模型大小，一般的工作流程是开始时选择相对较少的层和参数，然后逐渐增加层
的大小或增加新层，直到这种增加对验证损失的影响变得很小。

更大网络的训练损失很快就接近于零，网络的容量越大，它拟合训练数据（即得到很小的训练损失）的速度就越快，但也更容易过拟合
（导致训练损失和验证损失有很大差异）。

简单模型是指参数值分布的熵更小的模型（或参数更少的模型）。因此，一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，
从而限制模型的复杂度，这使得权重值的分布更加规则。这种方法叫作权重正则化，
其实现方法是向网络损失函数中添加与较大权重值相关的成本（cost）。
这个成本有两种形式。
1、L1 正则化（L1 regularization）：添加的成本与权重系数的绝对值［权重的 L1 范数（norm）］
成正比。
2、L2 正则化（L2 regularization）：添加的成本与权重系数的平方（权重的L2 范数）成正比。
神经网络的L2 正则化也叫权重衰减（weight decay）。不要被不同的名称搞混，权重衰减
与L2 正则化在数学上是完全相同的。
在Keras 中，添加权重正则化的方法是向层传递权重正则化项实例（weight regularizer
instance）作为关键字参数。
由于这个惩罚项只在训练时添加，所以这个网络的训练损失会比测试损失大很多。

dropout 是神经网络最有效也最常用的正则化方法之一对某一层使用dropout，就是在训练过程中随机将该层的一些输出特征舍
弃（设置为0）。dropout 比率（dropout rate）是被设为0 的特征所占的比例，通常在0.2~0.5
范围内。测试时没有单元被舍弃，而该层的输出值需要按dropout 比率缩小，因为这时比训练时
有更多的单元被激活，需要加以平衡。
dropout正则化的核心思想是在层的输出值中引入噪声，打破不显著的偶然模式。

防止神经网络过拟合的常用方法包括：
1、获取更多的训练数据
2、减小网络容量
3、添加权重正则化
4、添加 dropout


卷积运算
密集连接层和卷积层的根本区别在于，Dense 层从输入特征空间中学到的是全局模式（比如对于MNIST 数字，全局模式就是涉及所有像素的模式），而卷积层学到的是局部模式
这个重要特性使卷积神经网络具有以下两个有趣的性质。
1、卷积神经网络学到的模式具有平移不变性（translation invariant）。卷积神经网络在图像
右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。对于密集连
接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。这使得卷积神经网
络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需
要更少的训练样本就可以学到具有泛化能力的数据表示。
2、卷积神经网络可以学到模式的空间层次结构（spatial hierarchies of patterns）。
第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征
组成的更大的模式，以此类推。这使得卷积神经网络可以有效地学习越来越复杂、越来
越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。
对于包含两个空间轴（高度和宽度）和一个深度轴（也叫通道轴）的3D 张量，其卷积也
叫特征图（feature map）。对于RGB 图像，深度轴的维度大小等于3，因为图像有3 个颜色通道：
红色、绿色和蓝色。对于黑白图像（比如MNIST 数字图像），深度等于1（表示灰度等级）。卷
积运算从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图（output
feature map）。该输出特征图仍是一个3D 张量，具有宽度和高度，其深度可以任意取值，因为
输出深度是层的参数，深度轴的不同通道不再像RGB 输入那样代表特定颜色，而是代表过滤器
（filter）。过滤器对输入数据的某一方面进行编码，比如，单个过滤器可以从更高层次编码这样
一个概念：“输入中包含一张脸。”

卷积由以下两个关键参数所定义。
1、从输入中提取的图块尺寸：这些图块的大小通常是 3×3 或 5×5。本例中为 3×3，这是
很常见的选择。
2、输出特征图的深度：卷积所计算的过滤器的数量。本例第一层的深度为32，最后一层的
深度是64。

输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。
1、边界效应，可以通过对输入特征图进行填充来抵消。
2、使用了步幅（stride），稍后会给出其定义。

如果你希望输出特征图的空间维度与输入相同，那么可以使用填充（padding）。填充是在
输入特征图的每一边添加适当数目的行和列，使得每个输入方块都能作为卷积窗口的中心。
对于Conv2D 层，可以通过padding 参数来设置填充，这个参数有两个取值："valid" 表
示不使用填充（只使用有效的窗口位置）；"same" 表示“填充后输出的宽度和高度与输入相同”。
padding 参数的默认值为"valid"。
两个连续窗口的距离是卷积的一个参数，叫作步幅，默认值为1。也可
以使用步进卷积（strided convolution），即步幅大于1 的卷积。
为了对特征图进行下采样，我们不用步幅，而是通常使用最大池化（max-pooling）运算.
最大池化的作用：对特征图进行下采样.
最大池化是从输入特征图中提取窗口，并输出每个通道的最大值。它的概念与卷积类似，
但是最大池化使用硬编码的max 张量运算对局部图块进行变换，而不是使用学到的线性变换（卷
积核）。最大池化与卷积的最大不同之处在于，最大池化通常使用2×2 的窗口和步幅2，其目
的是将特征图下采样2 倍。与此相对的是，卷积通常使用3×3 窗口和步幅1。

使用下采样的原因，一是减少需要处理的特征图的元素个数，二是通过让连续
卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层
级结构。
注意，最大池化不是实现这种下采样的唯一方法。你已经知道，还可以在前一个卷积层中
使用步幅来实现。此外，你还可以使用平均池化来代替最大池化，其方法是将每个局部输入图
块变换为取该图块各通道的平均值，而不是最大值。但最大池化的效果往往比这些替代方法更好。
简而言之，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得
名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。因此，最合理的子采
样策略是首先生成密集的特征图（通过无步进的卷积），然后观察特征每个小图块上的最大激活，
而不是查看输入的稀疏窗口（通过步进卷积）或对输入图块取平均，因为后两种方法可能导致
错过或淡化特征是否存在的信息。

数据增强（data augmentation），它在计算机视觉领域是一种非常强大的降低过拟合的技术。
将深度学习应用于小型数据集的另外两个重要技巧：用预训练的网络做特征提
取，对预训练的网络进行微调。













